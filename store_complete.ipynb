{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quint\n",
      "Investigations into the Jamia Millia Islamia violence and Northeast Delhi riot cases were done impartially, and arrests were made after analysis of forensic evidence, the Delhi Police said on Monday, 20 April.The police's reaction came after some lawyers, activists and artistes criticised it over the handling of the cases.\"While investigating Jamia and northeast (Delhi) riot cases, Delhi Police has done its job sincerely and impartially,\" the Delhi Police tweeted.\"All the arrests made have been based on analysis of scientific and forensic evidence, including video footage, technical and other footprints,\" it said, adding that it “will not be deterred by the false propaganda and rumours floated by some vested elements who try to twist facts to their convenience.”Artistes Release Statement Against Delhi Police Arresting StudentsOver 20 film personalities, including Anurag Kashyap, Vishal Bhardwaj, Mahesh Bhatt, Ratna Pathak Shah, on Sunday, 19 April released a statement raising their voice against the arrest of students and activists by Delhi Police for protesting against CAA and also demanded their release.A Delhi court on Wednesday, 15 April sent a student of Jamia Millia Islamia, arrested for allegedly hatching a conspiracy to incite communal riots in northeast Delhi, to judicial custody for 14 days.Another student, who was arrested by the local police last week in connection with protests against the Citizenship (Amendment) Act in Delhi's Jaffrabad in February, was sent to two-day police custody.In a statement released on Twitter, the signatories said they are “shocked” to know that even as the country battles though a grave crisis of the coronavirus, the Delhi Police has arrested two students and several activists “who had participated in peaceful protests against the CAA”.\"To fight this pandemic the citizens and authorities need to stand by each other. By targeting activists taking advantage of the lockdown, when there is hardly even any media coverage of its actions, the Delhi Police is betraying the civic rights of the citizens.\"We urge the Delhi Police to stop abusing the lockdown, respect the human rights of our fellow citizens and put an end to this witch-hunt. We demand the release of these students and activists,\" the statement read.The signatories said many more students and activists are being called for questioning and interrogation by the police on daily basis and dubbed the action a “twisted fairy tale”.\"These activists are now being implicated in cases related to the communal violence in Delhi that took place in February. A riot in which the minorities suffered the maximum damage, both in terms of lives and livelihoods, has now become a pretext for the Delhi Police to further witch-hunt activists. Most of whom also come from the minority community,\" they further said in a statement.Calling the actions of Delhi Police as \"inhuman\", the personalities said the lockdown \"cannot be a lockdown of the rights of citizens\" and must not be \"abused by the authorities in this manner\".\"These actions of the Delhi Police are utterly inhuman and undemocratic. Making several people travel to police stations every day and then throwing some of them to jails also defeats the purpose of the lockdown and makes a mockery of social distancing.\"At a time when various governments are releasing under-trials from jail to relieve the pressure from the prisons and restrict chances of contamination. The Delhi Police is pushing students and activists into jail.\"The signatories include directors Aparna Sen, Hansal Mehta, Ashwini Chaudhary, Onir, Vinta Nanda, Neeraj Ghaywan, actor-directors Nandita Das, Konkona Sen Sharma, actors Sushant Singh, Zeeshan Ayyub, Sandhya Mridul, music composer Vishal Dadlani, among others.The signatories include directors Aparna Sen, Hansal Mehta, Ashwini Chaudhary, Onir, Vinta Nanda, Neeraj Ghaywan, actor-directors Nandita Das, Konkona Sen Sharma, actors Sushant Singh, Zeeshan Ayyub, Sandhya Mridul, music composer Vishal Dadlani, among others.\"In a democratic country such as ours, the Constitution gives us the right to protest and express our views against the government and its policies. Many people in the country and the world had condemned the draconian Citizenship Amendment Act.\"Our opposition to the CAA continues, as we see it as a bigoted law that strikes at the secular fabric of our country. We condemn this witch-hunt of students and activists because they exercised their constitutional right to protest against CAA/NRC/NPR,\" the statement read.Communal clashes had broken out in northeast Delhi on February 24 after violence between the citizenship law supporters and protesters spiralled out of control, leaving at least 53 people dead and around 200 injured.(An arrangement of two PTI reports) We&#39;ll get through this! Meanwhile, here&#39;s all you need to know about the Coronavirus outbreak to keep yourself safe, informed, and updated. (The Quint is now available on Telegram &amp; WhatsApp too, Click here to join.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prakhyat/.local/lib/python3.6/site-packages/ipykernel_launcher.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter,OrderedDict\n",
    "d=pd.read_csv(\"data1.0.csv\",encoding=\"latin1\")\n",
    "d.drop_duplicates(subset=[\"headlines\"],inplace=True)\n",
    "d.reset_index(drop=True,inplace=True)\n",
    "#d.describe()\n",
    "d[\"ctext\"]=[0 for i in range(len(d[\"text\"]))]\n",
    "count=0\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "        'Accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "        'X-Requested-With': 'XMLHttpRequest'\n",
    "    }\n",
    "\n",
    "newspaper={}\n",
    "for i,head in enumerate(d[\"headlines\"]):\n",
    "    #print(i)\n",
    "    if d[\"read_more\"][i]:\n",
    "        if len(d[\"read_more\"][i].split(\"/\"))>2:\n",
    "            link=d[\"read_more\"][i].split(\"/\")[2]\n",
    "            if link !=\"www.thequint.com\":\n",
    "                continue\n",
    "            #if link in newspaper:\n",
    "             #   newspaper[link]+=1\n",
    "            #else:\n",
    "             #   newspaper[link]=1\n",
    "            #continue\n",
    "            try:\n",
    "                r=requests.get(d[\"read_more\"][i],headers=headers)\n",
    "                #print(d[\"read_more\"][i])\n",
    "            except:\n",
    "                time.sleep(10)\n",
    "            #if i%300==0:\n",
    "                #d.to_csv(\"complete\"+str(i)+\".csv\", index=False)\n",
    "                #time.sleep(10)\n",
    "            if link==\"www.hindustantimes.com\":\n",
    "                continue\n",
    "                #r=requests.get(d[\"read_more\"][i])\n",
    "                print(\"hindustan times\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup)\n",
    "                #try:\n",
    "                    #txt=soup.find(\"div\",{\"itemprop\":\"articlebody\"}).getText()\n",
    "                txt=\"\"\n",
    "                for s in soup.find_all(\"div\",{\"class\":\"storyDetail\"})[0].find_all(\"p\")[:-1]:\n",
    "                    #print(s)\n",
    "                    txt=txt+s.getText()\n",
    "                count=count+1\n",
    "                d[\"ctext\"][i]=txt\n",
    "                #print(txt)\n",
    "                #except:pass\n",
    "            elif link==\"www.india.com\":\n",
    "                print(\"the india\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                txt=\"\"\n",
    "                #print(soup.find(\"div\",{\"class\":\"articleBody\"}).find_all(\"p\"))\n",
    "                #break\n",
    "                #print(maindiv)\n",
    "                #try:\n",
    "                for s in soup.find(\"div\",{\"class\":\"articleBody\"}).find_all(\"p\"):\n",
    "                    txt=txt+s.getText()\n",
    "                count=count+1\n",
    "                d[\"ctext\"][i]=txt\n",
    "                print(txt)\n",
    "                break\n",
    "                #except:pass\n",
    "            elif link==\"www.financialexpress.com\":\n",
    "                continue\n",
    "                print(\"financial express\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup)\n",
    "                #break\n",
    "                #print(soup.find(\"div\",{\"class\":\"post-summary\"}))\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"post-summary\"}).findAll(\"p\")[:-1]:\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"in.reuters.com\":\n",
    "                continue\n",
    "                print(\"reuter\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup.find(\"div\",{\"class\":\"StandardArticleBody_body\"}))\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"StandardArticleBody_body\"}).findAll(\"p\")[:-1]:\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.newindianexpress.com\":\n",
    "                continue\n",
    "                print(\"news india\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"articlestorycontent\"}).findAll(\"p\"):\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.reuters.com\":\n",
    "                print(\"reuter\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup.find(\"div\",{\"class\":\"StandardArticleBody_body\"}))\n",
    "                #break\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"StandardArticleBody_body\"}).findAll(\"p\")[:-1]:\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.deccanherald.com\":\n",
    "                print(\"reuter\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup.find(\"div\",{\"class\":\"content\"}))\n",
    "                #break\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"content\"}).findAll(\"p\"):\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.crictracker.com\":\n",
    "                print(\"reuter\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                #print(soup)\n",
    "                #break\n",
    "                txt=\"\"\n",
    "                try:\n",
    "                    for s in soup.find(\"div\",{\"class\":\"main-post-conatiner\"}).findAll(\"p\"):\n",
    "                        txt=txt+s.getText()\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.bloombergquint.com\":\n",
    "                print(\"bloombergquint\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                txt=\"\"\n",
    "                #print(soup.find_all(\"div\",{\"class\":\"story-element story-element-text\"}))\n",
    "                try:\n",
    "                    json_data = soup.find('script', text=re.compile(\"articleBody\"))\n",
    "                    for i in json_data:\n",
    "                        json_data=i\n",
    "                    txt=json.loads(json_data)[\"articleBody\"]\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            elif link==\"www.thequint.com\":\n",
    "                print(\"quint\")\n",
    "                soup=BeautifulSoup(r.content,\"lxml\")\n",
    "                txt=\"\"\n",
    "                #print(soup.find_all(\"div\",{\"class\":\"story-element story-element-text\"}))\n",
    "                try:\n",
    "                    json_data=soup.find('script', text=re.compile(\"articleBody\"))\n",
    "                    for i in json_data:\n",
    "                        json_data=i\n",
    "                    txt=json.loads(json_data)[0][\"articleBody\"]\n",
    "                    count=count+1\n",
    "                    d[\"ctext\"][i]=txt\n",
    "                    print(txt)\n",
    "                except:pass\n",
    "                break\n",
    "            \n",
    "#print(count)\n",
    "#d.to_csv(\"complete\"+str(i)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
